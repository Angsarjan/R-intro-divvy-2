---
title: "Introduction to R for data analysis"
author: Peter Carbonetto
output:
  beamer_presentation:
    template: beamer.tex
    keep_tex: false
---

```{r knitr-options, echo=FALSE}
knitr::opts_chunk$set(comment = "#",collapse = TRUE,fig.align = "center",
                      results = "hide", fig.show = "hide", message = FALSE,
		      warning = FALSE)
```

Aims of workshop
================

1. Work through the steps of a basic data analysis in R, starting with
   the "raw" source data and ending with evocative visualizations of the data.

2. Understand how to import data from a CSV file into an R data frame.

3. Use standard tools to summarize and manipulate data frames.

4. Use ggplot2 to create plots from the processed data.

4. Learn through "live coding"---this includes learning from our
mistakes!

Our project: Analyze 2016 & 2017 Divvy data
===========================================

+ Our goal is to study use of bike sharing services in Chicago.

+ We will use data made available from Divvy:

    - www.divvybikes.com/system-data

+ Much of the effort will be spent importing the data, inspecting the
  data, and preparing the data for analysis.

+ Once we have carefully prepared the data, we will be able to easily
  create evocative visualizations.

It's your choice
================

Your may choose to...

+ Use R on your laptop.

+ Use RStudio on your laptop.

+ Use R or RStudio (Desktop or Server) on the RCC cluster.

+ Pair up with your neighbour.

+ Follow what I do on the projector.

**Note:** If you use the RCC cluster I'm assuming you know how to set
up an interactive computing session with appropriate amount of time
and memory, load R or RStudio, and display graphics (e.g., using
ThinLinc). I can help troubleshoot.

Software we will use today
==========================

1. **R**

2. R packages **data.table**, **ggplot2** and **cowplot**.

3. **RStudio** (optional).

**Note:** I'm assuming you have already installed R and/or RStudio on
your laptop, or you are using the RCC cluster.

Outline of workshop
===================

*Add outline here.*

Outline of initial setup
========================

*Add outline of initial setup here.*

Initial setup
=============

+ WiFi

+ Power outlets

+ YubiKeys

+ Pace, questions (e.g., keyboard shortcuts).

Download or "clone" git repository
==================================

The first step is to download the workshop packet onto your computer
or onto the RCC cluster. Go to:

+ [**github.com/rcc-uchicago/R-intro-divvy-2**][github-repo]

To download, click green **"Clone or download"** button.

Or, if you have **git**, you can run this command:

```{bash download-repo, eval=FALSE}
git clone https://github.com/rcc-uchicago/
  R-intro-divvy-2.git
```

(Note the URL in the git command should not contain any spaces.)

What's in the workshop packet
=============================

```
R-intro-divvy-2
  /analysis # Scripts implementing data analyses.
  /code     # Additional R code used in analyses.
  /data     # Original ("raw") data.
  /docs     # Additional workshop materials.
  /output   # Processed data & results files.
```

Open the slides on your computer
================================

The PDF is useful for copying & pasting code from the slides.

+ The PDF is in the [**"docs"**](../docs) folder of the workshop packet.

+ You can also view the PDF by clicking the **"docs"** item in the file
  listing on the GitHub webpage.

Download the Divvy data
=======================

+ Disk space required: at least **2 GB**.

+ Download the 2016 & 2017 data files from here:

    + [**www.divvybikes.com/system-data**][divvy-data]

+ Download them to the [**"data"**](../data) folder.

+ You should have 4 ZIP files:

    ```
    Divvy_Trips_2016_Q1Q2.zip
    Divvy_Trips_2016_Q3Q4.zip
    Divvy_Trips_2017_Q1Q2.zip
    Divvy_Trips_2017_Q3Q4.zip
    ```

+ Unzip all of these files.

+ After unziping these files, you should have **15** CSV files.

[github-repo]: https://github.com/rcc-uchicago/R-intro-divvy-2
[divvy-data]: https://www.divvybikes.com/system-data

Set up your R environment
=========================

+ Launch R or RStudio.

+ *We will run all the code from the **"analysis"** folder*.

+ To change your working directory:

    + In R, use `getwd()` function.

    + In RStudio, select **Session > Set Working Directory > Choose
      Directory...`**

Before continuing, check your working directory:

```{r check-wd}
getwd()  # Should be .../analysis
```

Run `sessionInfo()`
===================

Check the version of R that you are using:

```{r check-version}
sessionInfo()
```

If you are using an older version of R (version 3.2 or earlier), you
should upgrade to the latest version. *Some of the examples may not
work in older versions of R.*

Check your R environment
========================

The R environment is where all variables and functions are stored and
accessed. Your R environment should be empty:

```{r check-env}
ls()
```

If you do see names of objects listed, it means your environment is
not empty, and you should restart R with a clean environment. (In
RStudio, go to **Session > Restart R**.)

Create a file to keep track of your analysis code
=================================================

+ In RStudio, select **File > R Script**.

+ Alternatively, use your favourite editor (emacs, vim, Atom, *etc*).

+ Add some comments to the tile to remind yourself what this file is
  for, e.g.,

    ```
    # R code I used to analyze Divvy data
	# during RCC workshop on May 1, 2018.
    ```

+ Save the file in the [**"analysis"**](../analysis) folder.
  Name the file whatever you'd like (e.g., `myanalysis.R`).

+ At this point, we are ready to start our analysis of the Divvy data.

Outline of workshop
===================

*Add outline of workshop here.*

Import the station data into R
==============================

Load the most recent available station data into an R "data frame":

```{r read-station-data}
stations <-
  read.csv("../data/Divvy_Stations_2017_Q3Q4.csv",
           stringsAsFactors = FALSE)
```

This creates a new "data frame" object in your environment:

```{r inspect-station-data-1}
ls()
class(stations)
```

What does `read.csv` do, and what is a "data frame"? We can find the
answers by running

```{r help-readcsv-dataframe, eval=FALSE}
help(read.csv)
help(data.frame)
```

Inspect the Divvy station data
==============================

Run these commands to inspect the station data:

```{r inspect-station-data}
nrow(stations)
ncol(stations)
head(stations)
tail(stations)
stations[1:6,]
summary(stations)
```

*What do we learn about the station data from running these
commands? Did we reveal any issues with these data?*

Take a closer look at the "dpcapacity" column
=============================================

Run these commands to take a closer look at the "dpcapacity" column:

```{r inspect-dpcapacity-data-1}
x <- stations$dpcapacity
class(x)
summary(x)
table(x)
quantile(x,seq(0,1,0.1))
```

*What did we learn about the Divvy stations from running these
commands?*

Take an even closer look at dpcapacity data
===========================================

It is interesting that a few of the Divvy bike stations are much
larger than the others, and some have no docks. Where are these
stations?

```{r inspect-dpcapacity-data-2}
subset(stations,dpcapacity == 0)
subset(stations,dpcapacity >= 40)
```

Alternatively, we can sort the table rows and inspect the top and
bottom rows:

```{r inspect-dpcapcity-data-3}
rows <- order(stations$dpcapacity,decreasing=TRUE)
stations <- stations[rows,]
head(stations)
tail(stations)
```

Take a closer look at the "city" column
=======================================

Above we inspected *numeric* data. How can we inspect non-numeric data
in R?

```{r inspect-city-data-1}
x <- stations$city
class(x)
summary(x)
```

Unfortunately, the summary is not very useful here. The key is to
convert the "city" column to a "factor" (a categorical variable):

```{r inspect-city-data-2}
x <- factor(stations$city)
class(x)
summary(x)
```

*What did we learn about the Divvy stations from running these
commands? What issue did we discover in the station data? How could we
fix this issue?*

Improving the "city" column
===========================

Let's fix this problem:

```{r revise-city-data-1}
rows <- which(stations$city == "Chicago ")
length(rows)
stations[rows,"city"] <- "Chicago"
```

We also observed that the "city" column is more useful if it is a
factor, so let's convert it to a factor:

```{r revise-city-data-2}
stations <- transform(stations,city = factor(city))
summary(stations)
```

Import the Divvy trip data into R
=================================

Previously, we used the `read.csv` function to import some of the
station data into R. Let's now use the same function to load the most
recent available trip data:

```{r read-trip-data}
trips <-
  read.csv("../data/Divvy_Trips_2017_Q4.csv",
           stringsAsFactors = FALSE)
```

You may find that this command look longer to run than
before. Consider that the trips data is much larger:

```{r trip-data-size}
nrow(trips)
ncol(trips)
```

This gives an opportunity to demonstrate a much faster method from the
`data.table` package for importing large data sets.

Import Divvy trip data using `fread`
====================================

Install the **data.table** package from CRAN:

```{r install-data-table, eval=FALSE}
install.packages("data.table")
```

Load the package functions into your environment:

```{r load-data-table}
library("data.table")
```

Now let's see how well the `fread` function performs:

```{r read-trip-data-better-1}
trips <- fread("../data/Divvy_Trips_2017_Q4.csv",
               stringsAsFactors = FALSE)
```

One annoying feature of `fread` is that it uses its own "data.table"
class, so we need to convert it to a data frame object if we want to
use it like other data frames:

```{r read-trip-data-better-2}
class(trips) <- "data.frame"
```

More about packages in R
========================

+ CRAN is the official package source (cran.r-project.org).

+ Other major sources: Bioconductor, GitHub.

+ *What packages are already installed?*
  `rownames(installed.packages())`.

+ *Where are the packages?* `.libPaths()`.

+ *How to learn more about a package?* `help(package = data.table)`.

+ "Vignettes" are also a great way to learn about a package, e.g.,
  `vignette("datatable-intro")`

A first glance at the trips data
================================

Let's use some of the same commands as before to quickly get an
overview of the trip data:

```{r inspect-trip-data}
nrow(trips)
ncol(trips)
head(trips)
summary(trips)
```

Unfortunately, the summary command isn't particularly informative for
many of the columns. We have the same problem as before—we should
convert some of the columns to factors.

Convert some columns to factors
===============================

Let's start by converting the "gender" column to a factor:

```{r convert-trip-data-1}
trips <- transform(trips,gender = factor(gender))
summary(trips$gender)
```

*What problem have we stumbled upon?*

Convert some columns to factors
===============================

In R, "missing data" should always be assigned the special value `NA`,
short for "not available" or "not assigned":

```{r convert-trip-data-2}
i <- which(trips$gender == "")
trips$gender[i] <- NA
trips <- transform(trips,gender = factor(gender))
summary(trips$gender)
```

Many functions in R will take care to handle missing data as long as
they are encoded as the special value `NA`.

Convert some columns to factors
===============================

Next, let's convert the "station" columns to factors:

```{r convert-trip-data-3}
trips <- transform(trips,
  from_station_name = factor(from_station_name),
  to_station_name = factor(to_station_name))
summary(trips)
```

The summary is now more informative. However, this is a better way to
convert the "station" columns to factors:

```{r convert-trip-data-4}
x     <- stations$name
trips <- transform(trips,
  from_station_name = factor(from_station_name,x),
  to_station_name = factor(to_station_name,x))
```

*Why is second approach better?*

Working with dates and times
============================

Like the categorical variables (the "factors"), the summaries for the
dates and times aren't particularly useful. Working with dates & times
iin R is more complicated, so for now I will only point out that the
`lubridate` package has lots of useful functions for working with
dates & times.

Take a closer look at the trips from U of C
===========================================

Having imported and prepared the data in R, let's take a close look
at the trip data departing from the central Divvy station the
University of Chicago campus.

```{r get-uc-trips}
uofstn   <- "University Ave & 57th St"
uc.trips <-
  subset(trips,from_station_name == uofstn)
nrow(uc.trips)
```

How do the ages of the riders at U of C compare to citywide riders?

```{r inspect-uc-trips-1}
summary(uc.trips$birthyear)
summary(trips$birthyear)
```

Inspect further the U of C trip data
====================================

It is also fun to look at the final destinations of all the riders who
started from 57th & University:

```{r inspect-uc-trips-2}
counts <- table(uc.trips$to_station_name)
counts <- counts[counts > 0]
sort(counts,decreasing = TRUE)
```

What is the destination for most riders? How many times did people
bike all the way to Millenium Park in Fall 2017?

Save your code & session state
==============================

It is important to periodically save your code and save the state of
your R environment just in case you accidentally quit or the program
crashes; e.g.,

```{r save-session-1, eval=FALSE}
save.image("../output/myanalysis.RData")
```

Preparing data is tedious
=========================

Data preparation is sometimes >90% of the effort!

+ *Many analysis mistakes are due to poor data preparation.*

Common issues include:

+ Formatting mistakes in CSV file.

+ Converting table columns to the appropriate data type.

+ Entry inconsistencies (e.g., "Chicago" vs. "Chicago ").

+ Missing data.

+ Many other examples of Bad Practice in recording data.

(And we haven't yet dealt with merging data from multiple files—this
usually creates more headaches!)

Moving beyond data preparation
==============================

*Add material here*

Outline of workshop
===================

*Add outline here.*

Import and merge the 2016 & 2017 Divvy data
===========================================

I wrote a function to read & prepare the 2016-2017 Divvy
data.

```{r load-functions}
library("data.table")
source("../code/functions.R")
ls()
```

Import and merge the 2016 & 2017 Divvy data
===========================================

This may take a few minutes to run.

```{r import-all-divvy-data}
tripfiles <- Sys.glob("../data/Divvy_Trips*.csv")
stnfile   <- "../data/Divvy_Stations_2017_Q3Q4.csv"
divvy     <- read.divvy.data(stnfile,tripfiles)
```

The output is a "list" containing two data frames:

```
stations <- divvy$stations
trips    <- divvy$trips
head(stations)
head(trips)
```

*How many more trips were taken in 2017 than in 2017? (Try using 
the  `summary` function.)*

Out first plot: a map of the Divvy stations
===========================================

The [ggplot2 package](https://github.com/tidyverse/ggplot2) is a
powerful (although not immediately intuitive) set of plotting
functions that extend the base plotting fuctions in R.

```{r install-ggplot, eval=FALSE}
install.packages("ggplot2")
```

Load the ggplot2 functions into your environment:

```{r load-ggplot}
library("ggplot2")
```

In only a few lines of code, we can create a plot of the Divvy
stations by geographic location (latitude & longitude):

```{r plot-station-map-1}
p <- ggplot(data    = stations,
            mapping = aes(x = longitude,
			              y = latitude)) +
  geom_point()
print(p)
```

Adjusting the plotting parameters
=================================

I'd like to suggest using the **cowplot** package, which has better
plotting parameter defaults.

```{r plot-station-map-2}
install.packages("cowplot")
library(cowplot)
p <- ggplot(data    = stations,
            mapping = aes(x = longitude,
			              y = latitude)) +
  geom_point(shape = 21,fill = "darkblue",
             color = "white",size = 2)
print(p)
```

There are many, many functions in the ggplot2 package for adjusting
plotting settings.

+ **ggplot2.tidyverse.org** is a great reference.

*What geographic features of Chicago are recognizable from this plot?*

Scale stations by the number of departures
==========================================

Next let's add an additional piece of information to this
visualization:

+ Amount of activity at each station (which should roughly correspond
to population density, but maybe not always).

To do this, we need to add a new column to the "stations" data frame
containing the total number departures, which is calculated from the
"trips" data frame:

```{r count-trips-per-station}
counts <- table(trips$from_station_id)
head(counts)
```

Check that counts are in the same order as stations:

```{r check-station-trip-counts}
all(names(counts) == stations$id)
```

Scale stations by the number of departures
==========================================

Add these trip counts to the "stations" data frame:

```{r add-counts-to-stations}
counts   <- as.vector(counts)
stations <- cbind(stations,
                  data.frame(departures = counts))
head(stations)
```

Let's use this column in our new plot:

```{r plot-station-map-3}
p <- ggplot(data = stations,
  mapping = aes(x = longitude,y = latitude,
				size = sqrt(departures))) +
  geom_point(shape = 21,fill = "darkblue",
             color = "white")
print(p)
```

*Why do we set the size of each point to `sqrt(departures)`?*

Compare biking activity in 2016 & 2017
======================================

Get the counts separately for 2016 and 2017. Again, we will use the
`subset` function for this:

```{r count-trips-by-year}
x <- table(subset(trips,
       start.year == 2016)$from_station_id)
y <- table(subset(trips,
       start.year == 2017)$from_station_id)
stations <-
  cbind(stations,
        data.frame(dep.2016 = as.vector(x),
		           dep.2017 = as.vector(y)))
```

Scatterplot of trips by station (2016 vs. 2017)
===============================================

```{r plot-2016-vs-2017-trips}
p <- ggplot(data = stations,
            mapping = aes(x = dep.2016,
			              y = dep.2017)) +
  geom_point(shape = 4,size = 1.5)
print(p)		
```

It is difficult to tell which stations had more trips in 2017—we need
to compare against the x = y line.

```
p <- p + geom_abline(slope = 1,color = "skyblue",
                     linetype = "dashed")
print(p)
```

*One station stands out because it has had a much larger increase in
trips than other stations. Where is this station located?*

Parting thoughts
================

*Add thoughts here.*


